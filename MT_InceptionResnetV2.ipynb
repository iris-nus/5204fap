{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k14f6srmwzn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "#from tensorflow.keras.applications.convnext import ConvNeXtTiny\n",
        "#from tensorflow.keras.applications.efficientnet import EfficientNetB2, EfficientNetB3\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet201\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "#from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "#from tensorflow.keras.applications.resnet_rs import ResNetRS50\n",
        "#from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications.vgg19 import VGG19\n",
        "#from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.layers import Add, AveragePooling2D, BatchNormalization, Conv2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Layer, MaxPool2D, ReLU, Resizing\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcXqfX6mHWja",
        "outputId": "f5d97c2c-fbba-4334-dc32-2f14a43646b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount your own google drive, after running the code, sign in with your own google account\n",
        "# To load the project dataset, you should add a shortcut of the project folder in your own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge58mX_RVFHi"
      },
      "outputs": [],
      "source": [
        "# paths\n",
        "proj_path = '/content/drive/MyDrive/DSA5204_FAP_Project'\n",
        "dataset_path = proj_path + '/Datasets/SCUT-FBP'\n",
        "image_path = dataset_path + '/Images/'\n",
        "rate_path = dataset_path + '/Rating_Collection' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPKfce2cmwzw",
        "outputId": "d19e3995-02e3-46c6-c23c-30ec233e21b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n",
            "Num GPUs Available 1\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(\"Num GPUs Available\", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMQVRiO6sx5h"
      },
      "source": [
        "## 1. Clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pdfmWpo33lp",
        "outputId": "1f4a39cd-7df7-44d5-a6dd-5c4c0e95869e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.9/dist-packages (0.9.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlSg-DoU33oL"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/Cleaned_Images/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ0qePOs33qg",
        "outputId": "42f1df07-833c-40e2-87ab-4d7ca08a6c86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5510/5510 [02:47<00:00, 32.82it/s]\n"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
        "\n",
        "file_list = glob.glob(image_path + '/*.jpg')\n",
        "\n",
        "BG_COLOR = (255, 255, 255)\n",
        "with mp_selfie_segmentation.SelfieSegmentation(model_selection = 0) as selfie_segmentation:\n",
        "    for i in tqdm(range(len(file_list))):\n",
        "        file_name = file_list[i].split('/')[-1]\n",
        "        image = cv2.imread(file_list[i])\n",
        "        image_height, image_width, _ = image.shape\n",
        "\n",
        "        results = selfie_segmentation.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
        "        \n",
        "        #fg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "        #fg_image[:] = MASK_COLOR\n",
        "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "        bg_image[:] = BG_COLOR\n",
        "\n",
        "        output_image = np.where(condition, image, bg_image)\n",
        "        \n",
        "        # cleaned images are under folder /DSA5204_FAP_Project/Datasets/SCUT-FBP/Cleaned_Images\n",
        "        cv2.imwrite( '/Cleaned_Images/' + file_name, output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUwTeCsrs7vh"
      },
      "source": [
        "## 2. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJLGrRUY33s-"
      },
      "outputs": [],
      "source": [
        "image_path='/Cleaned_Images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me9d7WI77cPE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2fodjKItGE6",
        "outputId": "1944288f-d5a2-480a-c7a9-42433d00cc3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5500/5500 [00:38<00:00, 144.70it/s]\n"
          ]
        }
      ],
      "source": [
        "# load data: y_arr = [rating, race, gender]\n",
        "def load_data(img_dir, label_dir):\n",
        "  all_ratings = pd.read_csv(label_dir, sep = ' ', header = None)\n",
        "  all_ratings.columns = ['img_path', 'rating']\n",
        "\n",
        "  img_arr = np.zeros([len(all_ratings), 112, 112, 3]) # because of RAM limit\n",
        "  y_arr = np.zeros([len(all_ratings), 3])\n",
        "\n",
        "  for i in tqdm(range(len(all_ratings))):\n",
        "  #for i in tqdm(range(500)):\n",
        "    file_name = all_ratings.iloc[i, 0]\n",
        "    race = file_name[0]\n",
        "    gender = file_name[1]\n",
        "    if race == 'A':\n",
        "      y_arr[i, 1] = 0\n",
        "    else:\n",
        "      y_arr[i, 1] = 1\n",
        "\n",
        "    if gender == 'M':\n",
        "      y_arr[i, 2] = 0\n",
        "    else:\n",
        "      y_arr[i, 2] = 1 \n",
        "        \n",
        "    y_arr[i, 0] = all_ratings.iloc[i, 1]\n",
        "    \n",
        "    img = tf.io.read_file(img_dir + file_name)\n",
        "    img = tf.image.decode_jpeg(img, channels = 3)\n",
        "    img = tf.keras.layers.Resizing(112, 112)(img)\n",
        "    img = preprocess_input(img)\n",
        "    img_arr[i] = img\n",
        "\n",
        "  return img_arr, y_arr\n",
        "\n",
        "img_arr, y_arr = load_data(image_path, rate_path + '/All_labels.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0Owfk8fuQrm"
      },
      "outputs": [],
      "source": [
        "#np.save('/content/drive/MyDrive/img_arr.npy', img_arr)\n",
        "#np.save('/content/drive/MyDrive/y_arr.npy', y_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhs5nJoFuTaU"
      },
      "outputs": [],
      "source": [
        "#img_arr = np.load('/content/drive/MyDrive/img_arr.npy')\n",
        "#y_arr = np.load('/content/drive/MyDrive/y_arr.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhdcQrt9tOPS"
      },
      "outputs": [],
      "source": [
        "img_full_train, img_test, y_full_train, y_test = train_test_split(img_arr, y_arr, stratify = y_arr[:, 2], test_size = 0.2, \n",
        "                                                                  random_state = 0)\n",
        "img_train, img_val, y_train, y_val = train_test_split(img_full_train, y_full_train, stratify = y_full_train[:, 2], \n",
        "                                                      test_size = 0.2, random_state = 0)\n",
        "\n",
        "rating_train = y_train[:, 0]\n",
        "rating_val = y_val[:, 0]\n",
        "rating_test = y_test[:, 0]\n",
        "\n",
        "gender_train = y_train[:, 1]\n",
        "gender_val = y_val[:, 1]\n",
        "gender_test = y_test[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5_2LU0EtEwZ"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyIYrBtpG_uK"
      },
      "outputs": [],
      "source": [
        "class Custom_Dropout(Layer):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super(Custom_Dropout, self).__init__(**kwargs)\n",
        "        self.rate = rate\n",
        "\n",
        "        def call(self, inputs, training = None):\n",
        "            if training:\n",
        "                return tf.nn.dropout(inputs, rate = self.rate)\n",
        "            return inputs\n",
        "\n",
        "        \n",
        "        \n",
        "class InceptionResNetV2_MT_Extension(Model):\n",
        "    def __init__(self):\n",
        "        super(InceptionResNetV2_MT_Extension, self).__init__()\n",
        "        \n",
        "        self.inception = InceptionResNetV2(input_shape=(112, 112, 3),include_top=False,weights='imagenet')\n",
        "        self.inception.trainable = False\n",
        "\n",
        "        self.fc1_rating = Dense(500, kernel_regularizer = L2(0.0005))\n",
        "        self.bn_fc1_rating = BatchNormalization()\n",
        "        self.fc2_rating = Dense(1, kernel_regularizer = L2(0.0005))\n",
        "        \n",
        "        self.fc1_gender = Dense(500, kernel_regularizer = L2(0.0005))\n",
        "        self.bn_fc1_gender = BatchNormalization()\n",
        "        self.fc2_gender = Dense(1, kernel_regularizer = L2(0.0005), activation = 'sigmoid')\n",
        "        \n",
        "        \n",
        "        self.global_avg_pool = GlobalAveragePooling2D()\n",
        "        self.flatten = Flatten()\n",
        "        self.dropout = Custom_Dropout(0.3)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def call(self, inputs, training = None):\n",
        "        x = self.global_avg_pool(self.inception(inputs))\n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x_rating = self.fc2_rating(self.dropout(self.bn_fc1_rating(self.fc1_rating(x))))\n",
        "        x_gender = self.fc2_gender(self.dropout(self.bn_fc1_gender(self.fc1_gender(x))))\n",
        "        \n",
        "        return x_rating, x_gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uWrrZVnKeDL"
      },
      "outputs": [],
      "source": [
        "Loss_Functions = {'output_1': 'mse', 'output_2': 'binary_crossentropy'}\n",
        "Loss_Weights = {'output_1': 5, 'output_2': 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQYl0dKwKuA6"
      },
      "outputs": [],
      "source": [
        "def custom_scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.01) \n",
        "\n",
        "    \n",
        "    \n",
        "required_callbacks = [\n",
        "    #tf.keras.callbacks.ModelCheckpoint(filepath = 'checkpoint', monitor = 'val_loss', save_best_only = True),\n",
        "    #tf.keras.callbacks.TensorBoard(),\n",
        "    tf.keras.callbacks.EarlyStopping(patience = 30, restore_best_weights = True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(custom_scheduler),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 10, verbose = 1, cooldown = 5, min_lr = 0.0000001),\n",
        "    tf.keras.callbacks.TerminateOnNaN()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot7u_MKWL87k"
      },
      "outputs": [],
      "source": [
        "adam_optimizer = Adam(learning_rate = 0.005)\n",
        "model = InceptionResNetV2_MT_Extension()\n",
        "model.compile(optimizer = adam_optimizer, loss = Loss_Functions, loss_weights = Loss_Weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3lCQwbrN3ck",
        "outputId": "caceac36-4fb8-4c24-d76b-619e157cdd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "141/141 [==============================] - 35s 98ms/step - loss: 20.0026 - output_1_loss: 3.6983 - output_2_loss: 0.5554 - val_loss: 3.6931 - val_output_1_loss: 0.4670 - val_output_2_loss: 0.5388 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 3.4444 - output_1_loss: 0.4558 - output_2_loss: 0.4449 - val_loss: 4.1768 - val_output_1_loss: 0.4793 - val_output_2_loss: 1.1463 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 3.4776 - output_1_loss: 0.4900 - output_2_loss: 0.4448 - val_loss: 9.5053 - val_output_1_loss: 0.9566 - val_output_2_loss: 4.1675 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 3.2796 - output_1_loss: 0.4616 - output_2_loss: 0.4621 - val_loss: 11.4073 - val_output_1_loss: 2.0238 - val_output_2_loss: 0.7999 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 3.3822 - output_1_loss: 0.5008 - output_2_loss: 0.4329 - val_loss: 9.9393 - val_output_1_loss: 1.6307 - val_output_2_loss: 1.3684 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 3.2243 - output_1_loss: 0.4798 - output_2_loss: 0.4319 - val_loss: 8.9863 - val_output_1_loss: 1.2219 - val_output_2_loss: 2.4901 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 3.2530 - output_1_loss: 0.4898 - output_2_loss: 0.4434 - val_loss: 7.9195 - val_output_1_loss: 1.4359 - val_output_2_loss: 0.3999 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 3.3707 - output_1_loss: 0.5234 - output_2_loss: 0.4253 - val_loss: 5.4644 - val_output_1_loss: 0.8476 - val_output_2_loss: 0.8895 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 3.1753 - output_1_loss: 0.4887 - output_2_loss: 0.4260 - val_loss: 7.6461 - val_output_1_loss: 1.3711 - val_output_2_loss: 0.4999 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 3.1831 - output_1_loss: 0.4941 - output_2_loss: 0.4324 - val_loss: 6.4306 - val_output_1_loss: 1.0322 - val_output_2_loss: 0.9991 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 3.3747 - output_1_loss: 0.5368 - output_2_loss: 0.4275\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024751245509833097.\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 3.3747 - output_1_loss: 0.5368 - output_2_loss: 0.4275 - val_loss: 5.6147 - val_output_1_loss: 0.6110 - val_output_2_loss: 2.3054 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.9198 - output_1_loss: 0.4529 - output_2_loss: 0.4126 - val_loss: 4.8775 - val_output_1_loss: 0.6434 - val_output_2_loss: 1.4279 - lr: 0.0025\n",
            "Epoch 13/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.9176 - output_1_loss: 0.4548 - output_2_loss: 0.4162 - val_loss: 5.9365 - val_output_1_loss: 1.0268 - val_output_2_loss: 0.5782 - lr: 0.0024\n",
            "Epoch 14/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.9125 - output_1_loss: 0.4567 - output_2_loss: 0.4117 - val_loss: 3.7370 - val_output_1_loss: 0.5985 - val_output_2_loss: 0.5350 - lr: 0.0024\n",
            "Epoch 15/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.9619 - output_1_loss: 0.4693 - output_2_loss: 0.4067 - val_loss: 6.1718 - val_output_1_loss: 1.0413 - val_output_2_loss: 0.7594 - lr: 0.0024\n",
            "Epoch 16/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.8882 - output_1_loss: 0.4581 - output_2_loss: 0.3964 - val_loss: 6.3206 - val_output_1_loss: 0.8140 - val_output_2_loss: 2.0532 - lr: 0.0024\n",
            "Epoch 17/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.9619 - output_1_loss: 0.4680 - output_2_loss: 0.4210 - val_loss: 3.6930 - val_output_1_loss: 0.4474 - val_output_2_loss: 1.2604 - lr: 0.0023\n",
            "Epoch 18/1000\n",
            "141/141 [==============================] - 8s 56ms/step - loss: 2.9918 - output_1_loss: 0.4785 - output_2_loss: 0.4079 - val_loss: 3.0748 - val_output_1_loss: 0.4978 - val_output_2_loss: 0.3977 - lr: 0.0023\n",
            "Epoch 19/1000\n",
            "141/141 [==============================] - 9s 62ms/step - loss: 3.0079 - output_1_loss: 0.4841 - output_2_loss: 0.4045 - val_loss: 3.8456 - val_output_1_loss: 0.6568 - val_output_2_loss: 0.3770 - lr: 0.0023\n",
            "Epoch 20/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.8659 - output_1_loss: 0.4565 - output_2_loss: 0.4042 - val_loss: 4.5881 - val_output_1_loss: 0.5059 - val_output_2_loss: 1.8835 - lr: 0.0023\n",
            "Epoch 21/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 3.0670 - output_1_loss: 0.4963 - output_2_loss: 0.4091 - val_loss: 3.1825 - val_output_1_loss: 0.5227 - val_output_2_loss: 0.3893 - lr: 0.0022\n",
            "Epoch 22/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.9926 - output_1_loss: 0.4822 - output_2_loss: 0.4053 - val_loss: 5.2191 - val_output_1_loss: 0.6576 - val_output_2_loss: 1.7620 - lr: 0.0022\n",
            "Epoch 23/1000\n",
            "141/141 [==============================] - 8s 56ms/step - loss: 2.9500 - output_1_loss: 0.4738 - output_2_loss: 0.4133 - val_loss: 2.7674 - val_output_1_loss: 0.4412 - val_output_2_loss: 0.3966 - lr: 0.0022\n",
            "Epoch 24/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.9495 - output_1_loss: 0.4774 - output_2_loss: 0.4021 - val_loss: 8.5781 - val_output_1_loss: 1.5733 - val_output_2_loss: 0.5532 - lr: 0.0022\n",
            "Epoch 25/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.9725 - output_1_loss: 0.4815 - output_2_loss: 0.4043 - val_loss: 6.5748 - val_output_1_loss: 1.1452 - val_output_2_loss: 0.6889 - lr: 0.0022\n",
            "Epoch 26/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.8258 - output_1_loss: 0.4539 - output_2_loss: 0.4019 - val_loss: 3.8943 - val_output_1_loss: 0.5622 - val_output_2_loss: 0.9353 - lr: 0.0021\n",
            "Epoch 27/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.9258 - output_1_loss: 0.4742 - output_2_loss: 0.4076 - val_loss: 3.6640 - val_output_1_loss: 0.6157 - val_output_2_loss: 0.4369 - lr: 0.0021\n",
            "Epoch 28/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.8186 - output_1_loss: 0.4547 - output_2_loss: 0.4026 - val_loss: 3.7405 - val_output_1_loss: 0.5374 - val_output_2_loss: 0.9130 - lr: 0.0021\n",
            "Epoch 29/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.8350 - output_1_loss: 0.4577 - output_2_loss: 0.4044 - val_loss: 3.1283 - val_output_1_loss: 0.5155 - val_output_2_loss: 0.4089 - lr: 0.0021\n",
            "Epoch 30/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.9629 - output_1_loss: 0.4822 - output_2_loss: 0.4042 - val_loss: 3.3169 - val_output_1_loss: 0.5426 - val_output_2_loss: 0.4633 - lr: 0.0020\n",
            "Epoch 31/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.9220 - output_1_loss: 0.4773 - output_2_loss: 0.3956 - val_loss: 4.4051 - val_output_1_loss: 0.5788 - val_output_2_loss: 1.3712 - lr: 0.0020\n",
            "Epoch 32/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.8314 - output_1_loss: 0.4584 - output_2_loss: 0.4008 - val_loss: 2.9319 - val_output_1_loss: 0.4825 - val_output_2_loss: 0.3842 - lr: 0.0020\n",
            "Epoch 33/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.8305 - output_1_loss: 0.4608 - output_2_loss: 0.3924\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0009931673994287848.\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.8305 - output_1_loss: 0.4608 - output_2_loss: 0.3924 - val_loss: 3.0114 - val_output_1_loss: 0.4485 - val_output_2_loss: 0.6419 - lr: 0.0020\n",
            "Epoch 34/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.7820 - output_1_loss: 0.4529 - output_2_loss: 0.3944 - val_loss: 5.9458 - val_output_1_loss: 1.0068 - val_output_2_loss: 0.7922 - lr: 9.8329e-04\n",
            "Epoch 35/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.7295 - output_1_loss: 0.4432 - output_2_loss: 0.3952 - val_loss: 3.9722 - val_output_1_loss: 0.6901 - val_output_2_loss: 0.4074 - lr: 9.7350e-04\n",
            "Epoch 36/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.7007 - output_1_loss: 0.4402 - output_2_loss: 0.3879 - val_loss: 3.6512 - val_output_1_loss: 0.6243 - val_output_2_loss: 0.4194 - lr: 9.6381e-04\n",
            "Epoch 37/1000\n",
            "141/141 [==============================] - 8s 57ms/step - loss: 2.7967 - output_1_loss: 0.4590 - output_2_loss: 0.3915 - val_loss: 2.7360 - val_output_1_loss: 0.4511 - val_output_2_loss: 0.3720 - lr: 9.5422e-04\n",
            "Epoch 38/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.7903 - output_1_loss: 0.4591 - output_2_loss: 0.3867 - val_loss: 2.7965 - val_output_1_loss: 0.4459 - val_output_2_loss: 0.4609 - lr: 9.4473e-04\n",
            "Epoch 39/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.7598 - output_1_loss: 0.4543 - output_2_loss: 0.3845 - val_loss: 3.3245 - val_output_1_loss: 0.4938 - val_output_2_loss: 0.7500 - lr: 9.3533e-04\n",
            "Epoch 40/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.7892 - output_1_loss: 0.4595 - output_2_loss: 0.3872 - val_loss: 5.5201 - val_output_1_loss: 0.6605 - val_output_2_loss: 2.1115 - lr: 9.2602e-04\n",
            "Epoch 41/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.7007 - output_1_loss: 0.4424 - output_2_loss: 0.3860 - val_loss: 4.6714 - val_output_1_loss: 0.8305 - val_output_2_loss: 0.4187 - lr: 9.1681e-04\n",
            "Epoch 42/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.7492 - output_1_loss: 0.4508 - output_2_loss: 0.3914 - val_loss: 5.0880 - val_output_1_loss: 0.6072 - val_output_2_loss: 1.9502 - lr: 9.0769e-04\n",
            "Epoch 43/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.7150 - output_1_loss: 0.4447 - output_2_loss: 0.3913 - val_loss: 4.4672 - val_output_1_loss: 0.5662 - val_output_2_loss: 1.5390 - lr: 8.9866e-04\n",
            "Epoch 44/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.7271 - output_1_loss: 0.4483 - output_2_loss: 0.3874 - val_loss: 4.5314 - val_output_1_loss: 0.7938 - val_output_2_loss: 0.4635 - lr: 8.8971e-04\n",
            "Epoch 45/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.7265 - output_1_loss: 0.4490 - output_2_loss: 0.3845 - val_loss: 2.7707 - val_output_1_loss: 0.4351 - val_output_2_loss: 0.4994 - lr: 8.8086e-04\n",
            "Epoch 46/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.6787 - output_1_loss: 0.4395 - output_2_loss: 0.3871 - val_loss: 7.1005 - val_output_1_loss: 1.3275 - val_output_2_loss: 0.3656 - lr: 8.7210e-04\n",
            "Epoch 47/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.7612 - output_1_loss: 0.4544 - output_2_loss: 0.3918\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0004317091661505401.\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.7612 - output_1_loss: 0.4544 - output_2_loss: 0.3918 - val_loss: 5.5762 - val_output_1_loss: 0.9945 - val_output_2_loss: 0.5068 - lr: 8.6342e-04\n",
            "Epoch 48/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.6269 - output_1_loss: 0.4324 - output_2_loss: 0.3709 - val_loss: 3.0244 - val_output_1_loss: 0.4383 - val_output_2_loss: 0.7415 - lr: 4.2741e-04\n",
            "Epoch 49/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.6784 - output_1_loss: 0.4420 - output_2_loss: 0.3781 - val_loss: 3.0741 - val_output_1_loss: 0.4388 - val_output_2_loss: 0.7909 - lr: 4.2316e-04\n",
            "Epoch 50/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.6088 - output_1_loss: 0.4297 - output_2_loss: 0.3729 - val_loss: 4.5606 - val_output_1_loss: 0.7864 - val_output_2_loss: 0.5428 - lr: 4.1895e-04\n",
            "Epoch 51/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.6136 - output_1_loss: 0.4307 - output_2_loss: 0.3756 - val_loss: 3.3465 - val_output_1_loss: 0.5802 - val_output_2_loss: 0.3625 - lr: 4.1478e-04\n",
            "Epoch 52/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.6099 - output_1_loss: 0.4301 - output_2_loss: 0.3776 - val_loss: 2.8632 - val_output_1_loss: 0.4814 - val_output_2_loss: 0.3756 - lr: 4.1065e-04\n",
            "Epoch 53/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.6125 - output_1_loss: 0.4319 - output_2_loss: 0.3734 - val_loss: 2.9126 - val_output_1_loss: 0.4900 - val_output_2_loss: 0.3842 - lr: 4.0657e-04\n",
            "Epoch 54/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.5991 - output_1_loss: 0.4289 - output_2_loss: 0.3772 - val_loss: 3.1994 - val_output_1_loss: 0.5382 - val_output_2_loss: 0.4322 - lr: 4.0252e-04\n",
            "Epoch 55/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.6256 - output_1_loss: 0.4324 - output_2_loss: 0.3876 - val_loss: 3.2053 - val_output_1_loss: 0.5058 - val_output_2_loss: 0.6008 - lr: 3.9852e-04\n",
            "Epoch 56/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.6037 - output_1_loss: 0.4304 - output_2_loss: 0.3774 - val_loss: 3.2464 - val_output_1_loss: 0.4371 - val_output_2_loss: 0.9874 - lr: 3.9455e-04\n",
            "Epoch 57/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.6359 - output_1_loss: 0.4373 - output_2_loss: 0.3741 - val_loss: 2.9053 - val_output_1_loss: 0.4916 - val_output_2_loss: 0.3725 - lr: 3.9063e-04\n",
            "Epoch 58/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.6032 - output_1_loss: 0.4300 - output_2_loss: 0.3801 - val_loss: 2.6906 - val_output_1_loss: 0.4245 - val_output_2_loss: 0.4966 - lr: 3.8674e-04\n",
            "Epoch 59/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.6076 - output_1_loss: 0.4321 - output_2_loss: 0.3759 - val_loss: 2.9616 - val_output_1_loss: 0.4456 - val_output_2_loss: 0.6632 - lr: 3.8289e-04\n",
            "Epoch 60/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.6003 - output_1_loss: 0.4314 - output_2_loss: 0.3728 - val_loss: 3.5423 - val_output_1_loss: 0.6113 - val_output_2_loss: 0.4138 - lr: 3.7908e-04\n",
            "Epoch 61/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.5984 - output_1_loss: 0.4298 - output_2_loss: 0.3788 - val_loss: 2.6691 - val_output_1_loss: 0.4362 - val_output_2_loss: 0.4190 - lr: 3.7531e-04\n",
            "Epoch 62/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.5906 - output_1_loss: 0.4282 - output_2_loss: 0.3807 - val_loss: 2.6873 - val_output_1_loss: 0.4318 - val_output_2_loss: 0.4604 - lr: 3.7158e-04\n",
            "Epoch 63/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.6047 - output_1_loss: 0.4317 - output_2_loss: 0.3789 - val_loss: 3.5449 - val_output_1_loss: 0.5955 - val_output_2_loss: 0.5007 - lr: 3.6788e-04\n",
            "Epoch 64/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.5774 - output_1_loss: 0.4273 - output_2_loss: 0.3748 - val_loss: 2.8070 - val_output_1_loss: 0.4731 - val_output_2_loss: 0.3769 - lr: 3.6422e-04\n",
            "Epoch 65/1000\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.5814 - output_1_loss: 0.4285 - output_2_loss: 0.3751 - val_loss: 2.7964 - val_output_1_loss: 0.4730 - val_output_2_loss: 0.3674 - lr: 3.6059e-04\n",
            "Epoch 66/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.6166 - output_1_loss: 0.4358 - output_2_loss: 0.3735 - val_loss: 3.5683 - val_output_1_loss: 0.6118 - val_output_2_loss: 0.4450 - lr: 3.5701e-04\n",
            "Epoch 67/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.6244 - output_1_loss: 0.4364 - output_2_loss: 0.3788 - val_loss: 5.2056 - val_output_1_loss: 0.5009 - val_output_2_loss: 2.6379 - lr: 3.5345e-04\n",
            "Epoch 68/1000\n",
            "141/141 [==============================] - 8s 60ms/step - loss: 2.5914 - output_1_loss: 0.4310 - output_2_loss: 0.3731 - val_loss: 2.7812 - val_output_1_loss: 0.4712 - val_output_2_loss: 0.3627 - lr: 3.4994e-04\n",
            "Epoch 69/1000\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.5903 - output_1_loss: 0.4295 - output_2_loss: 0.3780 - val_loss: 2.5963 - val_output_1_loss: 0.4250 - val_output_2_loss: 0.4082 - lr: 3.4645e-04\n",
            "Epoch 70/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.5998 - output_1_loss: 0.4330 - output_2_loss: 0.3722 - val_loss: 2.6892 - val_output_1_loss: 0.4526 - val_output_2_loss: 0.3647 - lr: 3.4301e-04\n",
            "Epoch 71/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.5668 - output_1_loss: 0.4264 - output_2_loss: 0.3737 - val_loss: 2.6892 - val_output_1_loss: 0.4532 - val_output_2_loss: 0.3628 - lr: 3.3959e-04\n",
            "Epoch 72/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.6037 - output_1_loss: 0.4333 - output_2_loss: 0.3765 - val_loss: 2.8834 - val_output_1_loss: 0.4785 - val_output_2_loss: 0.4307 - lr: 3.3622e-04\n",
            "Epoch 73/1000\n",
            "141/141 [==============================] - 8s 56ms/step - loss: 2.5812 - output_1_loss: 0.4295 - output_2_loss: 0.3738 - val_loss: 2.5951 - val_output_1_loss: 0.4318 - val_output_2_loss: 0.3767 - lr: 3.3287e-04\n",
            "Epoch 74/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.5596 - output_1_loss: 0.4260 - output_2_loss: 0.3712 - val_loss: 2.7641 - val_output_1_loss: 0.4681 - val_output_2_loss: 0.3659 - lr: 3.2956e-04\n",
            "Epoch 75/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5648 - output_1_loss: 0.4261 - output_2_loss: 0.3767 - val_loss: 4.4755 - val_output_1_loss: 0.5558 - val_output_2_loss: 1.6394 - lr: 3.2628e-04\n",
            "Epoch 76/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.5704 - output_1_loss: 0.4279 - output_2_loss: 0.3727 - val_loss: 2.7476 - val_output_1_loss: 0.4526 - val_output_2_loss: 0.4266 - lr: 3.2303e-04\n",
            "Epoch 77/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.5861 - output_1_loss: 0.4302 - output_2_loss: 0.3772 - val_loss: 2.9596 - val_output_1_loss: 0.4897 - val_output_2_loss: 0.4537 - lr: 3.1982e-04\n",
            "Epoch 78/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.6178 - output_1_loss: 0.4360 - output_2_loss: 0.3795 - val_loss: 3.3878 - val_output_1_loss: 0.5039 - val_output_2_loss: 0.8103 - lr: 3.1664e-04\n",
            "Epoch 79/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5508 - output_1_loss: 0.4242 - output_2_loss: 0.3722 - val_loss: 3.2496 - val_output_1_loss: 0.5597 - val_output_2_loss: 0.3944 - lr: 3.1349e-04\n",
            "Epoch 80/1000\n",
            "141/141 [==============================] - 9s 63ms/step - loss: 2.5775 - output_1_loss: 0.4292 - output_2_loss: 0.3753 - val_loss: 2.5440 - val_output_1_loss: 0.4233 - val_output_2_loss: 0.3715 - lr: 3.1037e-04\n",
            "Epoch 81/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.5612 - output_1_loss: 0.4259 - output_2_loss: 0.3755 - val_loss: 2.7856 - val_output_1_loss: 0.4737 - val_output_2_loss: 0.3607 - lr: 3.0728e-04\n",
            "Epoch 82/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5691 - output_1_loss: 0.4265 - output_2_loss: 0.3804 - val_loss: 3.0753 - val_output_1_loss: 0.4239 - val_output_2_loss: 0.9005 - lr: 3.0422e-04\n",
            "Epoch 83/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5653 - output_1_loss: 0.4269 - output_2_loss: 0.3756 - val_loss: 2.6715 - val_output_1_loss: 0.4477 - val_output_2_loss: 0.3781 - lr: 3.0119e-04\n",
            "Epoch 84/1000\n",
            "141/141 [==============================] - 9s 61ms/step - loss: 2.5862 - output_1_loss: 0.4321 - output_2_loss: 0.3709 - val_loss: 3.0310 - val_output_1_loss: 0.4922 - val_output_2_loss: 0.5162 - lr: 2.9820e-04\n",
            "Epoch 85/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5865 - output_1_loss: 0.4320 - output_2_loss: 0.3725 - val_loss: 3.4808 - val_output_1_loss: 0.5005 - val_output_2_loss: 0.9244 - lr: 2.9523e-04\n",
            "Epoch 86/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5819 - output_1_loss: 0.4300 - output_2_loss: 0.3777 - val_loss: 3.9081 - val_output_1_loss: 0.5035 - val_output_2_loss: 1.3355 - lr: 2.9229e-04\n",
            "Epoch 87/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.5580 - output_1_loss: 0.4261 - output_2_loss: 0.3737 - val_loss: 3.0297 - val_output_1_loss: 0.5154 - val_output_2_loss: 0.3999 - lr: 2.8938e-04\n",
            "Epoch 88/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.5767 - output_1_loss: 0.4301 - output_2_loss: 0.3728 - val_loss: 2.6636 - val_output_1_loss: 0.4356 - val_output_2_loss: 0.4314 - lr: 2.8650e-04\n",
            "Epoch 89/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5518 - output_1_loss: 0.4254 - output_2_loss: 0.3713 - val_loss: 3.1273 - val_output_1_loss: 0.5325 - val_output_2_loss: 0.4120 - lr: 2.8365e-04\n",
            "Epoch 90/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.5611 - output_1_loss: 0.4271 - output_2_loss: 0.3730\n",
            "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.00014041538815945387.\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5611 - output_1_loss: 0.4271 - output_2_loss: 0.3730 - val_loss: 3.2325 - val_output_1_loss: 0.4436 - val_output_2_loss: 0.9624 - lr: 2.8083e-04\n",
            "Epoch 91/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.5149 - output_1_loss: 0.4185 - output_2_loss: 0.3708 - val_loss: 2.6494 - val_output_1_loss: 0.4335 - val_output_2_loss: 0.4311 - lr: 1.3902e-04\n",
            "Epoch 92/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5086 - output_1_loss: 0.4183 - output_2_loss: 0.3666 - val_loss: 2.6423 - val_output_1_loss: 0.4370 - val_output_2_loss: 0.4074 - lr: 1.3763e-04\n",
            "Epoch 93/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.5355 - output_1_loss: 0.4228 - output_2_loss: 0.3718 - val_loss: 2.5184 - val_output_1_loss: 0.4214 - val_output_2_loss: 0.3621 - lr: 1.3627e-04\n",
            "Epoch 94/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.5001 - output_1_loss: 0.4167 - output_2_loss: 0.3680 - val_loss: 2.5723 - val_output_1_loss: 0.4233 - val_output_2_loss: 0.4076 - lr: 1.3491e-04\n",
            "Epoch 95/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.5045 - output_1_loss: 0.4170 - output_2_loss: 0.3716 - val_loss: 2.7698 - val_output_1_loss: 0.4657 - val_output_2_loss: 0.3931 - lr: 1.3357e-04\n",
            "Epoch 96/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.5021 - output_1_loss: 0.4164 - output_2_loss: 0.3724 - val_loss: 2.8216 - val_output_1_loss: 0.4824 - val_output_2_loss: 0.3620 - lr: 1.3224e-04\n",
            "Epoch 97/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5079 - output_1_loss: 0.4184 - output_2_loss: 0.3686 - val_loss: 2.5606 - val_output_1_loss: 0.4284 - val_output_2_loss: 0.3716 - lr: 1.3092e-04\n",
            "Epoch 98/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4882 - output_1_loss: 0.4145 - output_2_loss: 0.3689 - val_loss: 2.6924 - val_output_1_loss: 0.4485 - val_output_2_loss: 0.4031 - lr: 1.2962e-04\n",
            "Epoch 99/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5016 - output_1_loss: 0.4177 - output_2_loss: 0.3668 - val_loss: 2.5711 - val_output_1_loss: 0.4327 - val_output_2_loss: 0.3615 - lr: 1.2833e-04\n",
            "Epoch 100/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.5075 - output_1_loss: 0.4200 - output_2_loss: 0.3614 - val_loss: 2.6708 - val_output_1_loss: 0.4389 - val_output_2_loss: 0.4307 - lr: 1.2705e-04\n",
            "Epoch 101/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.5158 - output_1_loss: 0.4212 - output_2_loss: 0.3643 - val_loss: 2.6434 - val_output_1_loss: 0.4484 - val_output_2_loss: 0.3563 - lr: 1.2579e-04\n",
            "Epoch 102/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.5049 - output_1_loss: 0.4190 - output_2_loss: 0.3650 - val_loss: 3.3007 - val_output_1_loss: 0.4655 - val_output_2_loss: 0.9285 - lr: 1.2454e-04\n",
            "Epoch 103/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4951 - output_1_loss: 0.4163 - output_2_loss: 0.3691 - val_loss: 2.5224 - val_output_1_loss: 0.4240 - val_output_2_loss: 0.3580 - lr: 1.2330e-04\n",
            "Epoch 104/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4889 - output_1_loss: 0.4148 - output_2_loss: 0.3705\n",
            "Epoch 104: ReduceLROnPlateau reducing learning rate to 6.103563646320254e-05.\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4889 - output_1_loss: 0.4148 - output_2_loss: 0.3705 - val_loss: 2.5841 - val_output_1_loss: 0.4314 - val_output_2_loss: 0.3831 - lr: 1.2207e-04\n",
            "Epoch 105/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4724 - output_1_loss: 0.4131 - output_2_loss: 0.3630 - val_loss: 2.6547 - val_output_1_loss: 0.4296 - val_output_2_loss: 0.4628 - lr: 6.0428e-05\n",
            "Epoch 106/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4849 - output_1_loss: 0.4153 - output_2_loss: 0.3648 - val_loss: 2.6934 - val_output_1_loss: 0.4449 - val_output_2_loss: 0.4256 - lr: 5.9827e-05\n",
            "Epoch 107/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4691 - output_1_loss: 0.4125 - output_2_loss: 0.3632 - val_loss: 2.7821 - val_output_1_loss: 0.4307 - val_output_2_loss: 0.5855 - lr: 5.9232e-05\n",
            "Epoch 108/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4822 - output_1_loss: 0.4148 - output_2_loss: 0.3653 - val_loss: 2.7755 - val_output_1_loss: 0.4207 - val_output_2_loss: 0.6294 - lr: 5.8642e-05\n",
            "Epoch 109/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4825 - output_1_loss: 0.4157 - output_2_loss: 0.3616 - val_loss: 2.5517 - val_output_1_loss: 0.4259 - val_output_2_loss: 0.3797 - lr: 5.8059e-05\n",
            "Epoch 110/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4766 - output_1_loss: 0.4142 - output_2_loss: 0.3633 - val_loss: 2.5626 - val_output_1_loss: 0.4259 - val_output_2_loss: 0.3909 - lr: 5.7481e-05\n",
            "Epoch 111/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.4724 - output_1_loss: 0.4141 - output_2_loss: 0.3599 - val_loss: 2.5140 - val_output_1_loss: 0.4232 - val_output_2_loss: 0.3563 - lr: 5.6909e-05\n",
            "Epoch 112/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4781 - output_1_loss: 0.4155 - output_2_loss: 0.3589 - val_loss: 2.7045 - val_output_1_loss: 0.4428 - val_output_2_loss: 0.4486 - lr: 5.6343e-05\n",
            "Epoch 113/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4619 - output_1_loss: 0.4114 - output_2_loss: 0.3633 - val_loss: 3.5323 - val_output_1_loss: 0.4267 - val_output_2_loss: 1.3572 - lr: 5.5782e-05\n",
            "Epoch 114/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4507 - output_1_loss: 0.4104 - output_2_loss: 0.3571 - val_loss: 2.7467 - val_output_1_loss: 0.4308 - val_output_2_loss: 0.5517 - lr: 5.5227e-05\n",
            "Epoch 115/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4576 - output_1_loss: 0.4117 - output_2_loss: 0.3582 - val_loss: 2.5685 - val_output_1_loss: 0.4202 - val_output_2_loss: 0.4266 - lr: 5.4678e-05\n",
            "Epoch 116/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4706 - output_1_loss: 0.4127 - output_2_loss: 0.3664 - val_loss: 2.6690 - val_output_1_loss: 0.4179 - val_output_2_loss: 0.5390 - lr: 5.4134e-05\n",
            "Epoch 117/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4549 - output_1_loss: 0.4105 - output_2_loss: 0.3616 - val_loss: 2.6045 - val_output_1_loss: 0.4194 - val_output_2_loss: 0.4668 - lr: 5.3595e-05\n",
            "Epoch 118/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4498 - output_1_loss: 0.4107 - output_2_loss: 0.3556 - val_loss: 2.5349 - val_output_1_loss: 0.4178 - val_output_2_loss: 0.4053 - lr: 5.3062e-05\n",
            "Epoch 119/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4735 - output_1_loss: 0.4139 - output_2_loss: 0.3638 - val_loss: 2.6264 - val_output_1_loss: 0.4443 - val_output_2_loss: 0.3647 - lr: 5.2534e-05\n",
            "Epoch 120/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4530 - output_1_loss: 0.4103 - output_2_loss: 0.3611 - val_loss: 2.5879 - val_output_1_loss: 0.4353 - val_output_2_loss: 0.3714 - lr: 5.2011e-05\n",
            "Epoch 121/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4566 - output_1_loss: 0.4109 - output_2_loss: 0.3620\n",
            "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.574681093392428e-05.\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4566 - output_1_loss: 0.4109 - output_2_loss: 0.3620 - val_loss: 2.6731 - val_output_1_loss: 0.4186 - val_output_2_loss: 0.5403 - lr: 5.1494e-05\n",
            "Epoch 122/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4530 - output_1_loss: 0.4116 - output_2_loss: 0.3555 - val_loss: 2.6566 - val_output_1_loss: 0.4224 - val_output_2_loss: 0.5050 - lr: 2.5491e-05\n",
            "Epoch 123/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4532 - output_1_loss: 0.4108 - output_2_loss: 0.3596 - val_loss: 2.5369 - val_output_1_loss: 0.4286 - val_output_2_loss: 0.3544 - lr: 2.5237e-05\n",
            "Epoch 124/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.4666 - output_1_loss: 0.4128 - output_2_loss: 0.3631 - val_loss: 2.4927 - val_output_1_loss: 0.4182 - val_output_2_loss: 0.3621 - lr: 2.4986e-05\n",
            "Epoch 125/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4509 - output_1_loss: 0.4102 - output_2_loss: 0.3602 - val_loss: 2.6431 - val_output_1_loss: 0.4177 - val_output_2_loss: 0.5153 - lr: 2.4737e-05\n",
            "Epoch 126/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4636 - output_1_loss: 0.4132 - output_2_loss: 0.3583 - val_loss: 2.5621 - val_output_1_loss: 0.4317 - val_output_2_loss: 0.3641 - lr: 2.4491e-05\n",
            "Epoch 127/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4297 - output_1_loss: 0.4066 - output_2_loss: 0.3577 - val_loss: 2.5956 - val_output_1_loss: 0.4183 - val_output_2_loss: 0.4648 - lr: 2.4247e-05\n",
            "Epoch 128/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4573 - output_1_loss: 0.4108 - output_2_loss: 0.3643 - val_loss: 2.5335 - val_output_1_loss: 0.4280 - val_output_2_loss: 0.3544 - lr: 2.4006e-05\n",
            "Epoch 129/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4429 - output_1_loss: 0.4096 - output_2_loss: 0.3560 - val_loss: 2.6974 - val_output_1_loss: 0.4581 - val_output_2_loss: 0.3677 - lr: 2.3767e-05\n",
            "Epoch 130/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4424 - output_1_loss: 0.4088 - output_2_loss: 0.3594 - val_loss: 2.5009 - val_output_1_loss: 0.4188 - val_output_2_loss: 0.3678 - lr: 2.3531e-05\n",
            "Epoch 131/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.4543 - output_1_loss: 0.4125 - output_2_loss: 0.3531 - val_loss: 2.4801 - val_output_1_loss: 0.4171 - val_output_2_loss: 0.3558 - lr: 2.3297e-05\n",
            "Epoch 132/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4447 - output_1_loss: 0.4109 - output_2_loss: 0.3513 - val_loss: 2.9888 - val_output_1_loss: 0.4170 - val_output_2_loss: 0.8653 - lr: 2.3065e-05\n",
            "Epoch 133/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4276 - output_1_loss: 0.4067 - output_2_loss: 0.3557 - val_loss: 2.5698 - val_output_1_loss: 0.4261 - val_output_2_loss: 0.4009 - lr: 2.2835e-05\n",
            "Epoch 134/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4429 - output_1_loss: 0.4090 - output_2_loss: 0.3594 - val_loss: 2.4984 - val_output_1_loss: 0.4184 - val_output_2_loss: 0.3679 - lr: 2.2608e-05\n",
            "Epoch 135/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4286 - output_1_loss: 0.4065 - output_2_loss: 0.3576 - val_loss: 2.9609 - val_output_1_loss: 0.4168 - val_output_2_loss: 0.8386 - lr: 2.2383e-05\n",
            "Epoch 136/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4170 - output_1_loss: 0.4052 - output_2_loss: 0.3526 - val_loss: 2.6823 - val_output_1_loss: 0.4374 - val_output_2_loss: 0.4571 - lr: 2.2160e-05\n",
            "Epoch 137/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4470 - output_1_loss: 0.4097 - output_2_loss: 0.3600 - val_loss: 2.5045 - val_output_1_loss: 0.4217 - val_output_2_loss: 0.3579 - lr: 2.1940e-05\n",
            "Epoch 138/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4302 - output_1_loss: 0.4074 - output_2_loss: 0.3549 - val_loss: 2.6557 - val_output_1_loss: 0.4505 - val_output_2_loss: 0.3653 - lr: 2.1722e-05\n",
            "Epoch 139/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4363 - output_1_loss: 0.4097 - output_2_loss: 0.3495 - val_loss: 2.9099 - val_output_1_loss: 0.4366 - val_output_2_loss: 0.6888 - lr: 2.1506e-05\n",
            "Epoch 140/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4373 - output_1_loss: 0.4092 - output_2_loss: 0.3535 - val_loss: 3.1332 - val_output_1_loss: 0.4287 - val_output_2_loss: 0.9515 - lr: 2.1292e-05\n",
            "Epoch 141/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4245 - output_1_loss: 0.4059 - output_2_loss: 0.3569\n",
            "Epoch 141: ReduceLROnPlateau reducing learning rate to 1.053985397447832e-05.\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4245 - output_1_loss: 0.4059 - output_2_loss: 0.3569 - val_loss: 2.5014 - val_output_1_loss: 0.4221 - val_output_2_loss: 0.3531 - lr: 2.1080e-05\n",
            "Epoch 142/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4249 - output_1_loss: 0.4067 - output_2_loss: 0.3534 - val_loss: 2.4886 - val_output_1_loss: 0.4174 - val_output_2_loss: 0.3639 - lr: 1.0435e-05\n",
            "Epoch 143/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4251 - output_1_loss: 0.4064 - output_2_loss: 0.3554 - val_loss: 2.4808 - val_output_1_loss: 0.4175 - val_output_2_loss: 0.3555 - lr: 1.0331e-05\n",
            "Epoch 144/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.4206 - output_1_loss: 0.4061 - output_2_loss: 0.3523 - val_loss: 2.4743 - val_output_1_loss: 0.4160 - val_output_2_loss: 0.3564 - lr: 1.0228e-05\n",
            "Epoch 145/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.4369 - output_1_loss: 0.4082 - output_2_loss: 0.3582 - val_loss: 2.5760 - val_output_1_loss: 0.4366 - val_output_2_loss: 0.3552 - lr: 1.0127e-05\n",
            "Epoch 146/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4228 - output_1_loss: 0.4054 - output_2_loss: 0.3581 - val_loss: 2.5616 - val_output_1_loss: 0.4185 - val_output_2_loss: 0.4316 - lr: 1.0026e-05\n",
            "Epoch 147/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4156 - output_1_loss: 0.4062 - output_2_loss: 0.3468 - val_loss: 2.4772 - val_output_1_loss: 0.4162 - val_output_2_loss: 0.3586 - lr: 9.9261e-06\n",
            "Epoch 148/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4204 - output_1_loss: 0.4054 - output_2_loss: 0.3560 - val_loss: 2.4953 - val_output_1_loss: 0.4159 - val_output_2_loss: 0.3784 - lr: 9.8273e-06\n",
            "Epoch 149/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4239 - output_1_loss: 0.4058 - output_2_loss: 0.3576 - val_loss: 2.5232 - val_output_1_loss: 0.4168 - val_output_2_loss: 0.4016 - lr: 9.7295e-06\n",
            "Epoch 150/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4198 - output_1_loss: 0.4054 - output_2_loss: 0.3552 - val_loss: 2.4820 - val_output_1_loss: 0.4183 - val_output_2_loss: 0.3533 - lr: 9.6327e-06\n",
            "Epoch 151/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4136 - output_1_loss: 0.4040 - output_2_loss: 0.3562 - val_loss: 2.4999 - val_output_1_loss: 0.4163 - val_output_2_loss: 0.3808 - lr: 9.5369e-06\n",
            "Epoch 152/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4107 - output_1_loss: 0.4041 - output_2_loss: 0.3528 - val_loss: 2.4942 - val_output_1_loss: 0.4174 - val_output_2_loss: 0.3700 - lr: 9.4420e-06\n",
            "Epoch 153/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4155 - output_1_loss: 0.4048 - output_2_loss: 0.3541 - val_loss: 2.5068 - val_output_1_loss: 0.4185 - val_output_2_loss: 0.3772 - lr: 9.3480e-06\n",
            "Epoch 154/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4192 - output_1_loss: 0.4054 - output_2_loss: 0.3547 - val_loss: 2.4869 - val_output_1_loss: 0.4159 - val_output_2_loss: 0.3700 - lr: 9.2550e-06\n",
            "Epoch 155/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4417 - output_1_loss: 0.4095 - output_2_loss: 0.3567\n",
            "Epoch 155: ReduceLROnPlateau reducing learning rate to 4.581454959406983e-06.\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.4417 - output_1_loss: 0.4095 - output_2_loss: 0.3567 - val_loss: 2.6205 - val_output_1_loss: 0.4221 - val_output_2_loss: 0.4726 - lr: 9.1629e-06\n",
            "Epoch 156/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4277 - output_1_loss: 0.4080 - output_2_loss: 0.3507 - val_loss: 2.4917 - val_output_1_loss: 0.4160 - val_output_2_loss: 0.3747 - lr: 4.5359e-06\n",
            "Epoch 157/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4143 - output_1_loss: 0.4045 - output_2_loss: 0.3544 - val_loss: 2.4888 - val_output_1_loss: 0.4177 - val_output_2_loss: 0.3631 - lr: 4.4907e-06\n",
            "Epoch 158/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4087 - output_1_loss: 0.4042 - output_2_loss: 0.3507 - val_loss: 2.4915 - val_output_1_loss: 0.4198 - val_output_2_loss: 0.3551 - lr: 4.4461e-06\n",
            "Epoch 159/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4188 - output_1_loss: 0.4062 - output_2_loss: 0.3506 - val_loss: 2.4750 - val_output_1_loss: 0.4163 - val_output_2_loss: 0.3562 - lr: 4.4018e-06\n",
            "Epoch 160/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4221 - output_1_loss: 0.4053 - output_2_loss: 0.3582 - val_loss: 2.4902 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3738 - lr: 4.3580e-06\n",
            "Epoch 161/1000\n",
            "141/141 [==============================] - 8s 54ms/step - loss: 2.4068 - output_1_loss: 0.4038 - output_2_loss: 0.3508 - val_loss: 2.4851 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3689 - lr: 4.3147e-06\n",
            "Epoch 162/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4096 - output_1_loss: 0.4051 - output_2_loss: 0.3472 - val_loss: 2.4886 - val_output_1_loss: 0.4167 - val_output_2_loss: 0.3677 - lr: 4.2717e-06\n",
            "Epoch 163/1000\n",
            "141/141 [==============================] - 8s 55ms/step - loss: 2.4334 - output_1_loss: 0.4083 - output_2_loss: 0.3549 - val_loss: 2.4696 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3547 - lr: 4.2292e-06\n",
            "Epoch 164/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4066 - output_1_loss: 0.4040 - output_2_loss: 0.3493 - val_loss: 2.4726 - val_output_1_loss: 0.4163 - val_output_2_loss: 0.3540 - lr: 4.1871e-06\n",
            "Epoch 165/1000\n",
            "141/141 [==============================] - 8s 56ms/step - loss: 2.3932 - output_1_loss: 0.4013 - output_2_loss: 0.3494 - val_loss: 2.4763 - val_output_1_loss: 0.4169 - val_output_2_loss: 0.3546 - lr: 4.1455e-06\n",
            "Epoch 166/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4155 - output_1_loss: 0.4055 - output_2_loss: 0.3509 - val_loss: 2.4831 - val_output_1_loss: 0.4160 - val_output_2_loss: 0.3661 - lr: 4.1042e-06\n",
            "Epoch 167/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4218 - output_1_loss: 0.4063 - output_2_loss: 0.3534 - val_loss: 2.4735 - val_output_1_loss: 0.4164 - val_output_2_loss: 0.3546 - lr: 4.0634e-06\n",
            "Epoch 168/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4133 - output_1_loss: 0.4047 - output_2_loss: 0.3529 - val_loss: 2.5006 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3846 - lr: 4.0230e-06\n",
            "Epoch 169/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4093 - output_1_loss: 0.4047 - output_2_loss: 0.3490 - val_loss: 2.4729 - val_output_1_loss: 0.4160 - val_output_2_loss: 0.3558 - lr: 3.9829e-06\n",
            "Epoch 170/1000\n",
            "141/141 [==============================] - 8s 60ms/step - loss: 2.4099 - output_1_loss: 0.4044 - output_2_loss: 0.3507 - val_loss: 2.5033 - val_output_1_loss: 0.4167 - val_output_2_loss: 0.3830 - lr: 3.9433e-06\n",
            "Epoch 171/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4138 - output_1_loss: 0.4049 - output_2_loss: 0.3524 - val_loss: 2.4781 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3622 - lr: 3.9041e-06\n",
            "Epoch 172/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4053 - output_1_loss: 0.4038 - output_2_loss: 0.3494 - val_loss: 2.4709 - val_output_1_loss: 0.4159 - val_output_2_loss: 0.3545 - lr: 3.8652e-06\n",
            "Epoch 173/1000\n",
            "140/141 [============================>.] - ETA: 0s - loss: 2.4084 - output_1_loss: 0.4046 - output_2_loss: 0.3483\n",
            "Epoch 173: ReduceLROnPlateau reducing learning rate to 1.9133769910695264e-06.\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4116 - output_1_loss: 0.4051 - output_2_loss: 0.3492 - val_loss: 2.4778 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3616 - lr: 3.8268e-06\n",
            "Epoch 174/1000\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.4128 - output_1_loss: 0.4047 - output_2_loss: 0.3523 - val_loss: 2.4786 - val_output_1_loss: 0.4160 - val_output_2_loss: 0.3619 - lr: 1.8943e-06\n",
            "Epoch 175/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4149 - output_1_loss: 0.4065 - output_2_loss: 0.3452 - val_loss: 2.4800 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3643 - lr: 1.8755e-06\n",
            "Epoch 176/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4258 - output_1_loss: 0.4073 - output_2_loss: 0.3524 - val_loss: 2.4824 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3663 - lr: 1.8568e-06\n",
            "Epoch 177/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4245 - output_1_loss: 0.4075 - output_2_loss: 0.3500 - val_loss: 2.4702 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3552 - lr: 1.8384e-06\n",
            "Epoch 178/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4057 - output_1_loss: 0.4047 - output_2_loss: 0.3453 - val_loss: 2.4743 - val_output_1_loss: 0.4159 - val_output_2_loss: 0.3578 - lr: 1.8201e-06\n",
            "Epoch 179/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4166 - output_1_loss: 0.4064 - output_2_loss: 0.3479 - val_loss: 2.4816 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3664 - lr: 1.8020e-06\n",
            "Epoch 180/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4165 - output_1_loss: 0.4052 - output_2_loss: 0.3534 - val_loss: 2.4893 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3739 - lr: 1.7840e-06\n",
            "Epoch 181/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4159 - output_1_loss: 0.4054 - output_2_loss: 0.3522 - val_loss: 2.4703 - val_output_1_loss: 0.4154 - val_output_2_loss: 0.3565 - lr: 1.7663e-06\n",
            "Epoch 182/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4137 - output_1_loss: 0.4054 - output_2_loss: 0.3499 - val_loss: 2.4706 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3553 - lr: 1.7487e-06\n",
            "Epoch 183/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4152 - output_1_loss: 0.4059 - output_2_loss: 0.3485 - val_loss: 2.4719 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3569 - lr: 1.7313e-06\n",
            "Epoch 184/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4066 - output_1_loss: 0.4033 - output_2_loss: 0.3533 - val_loss: 2.4726 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3573 - lr: 1.7141e-06\n",
            "Epoch 185/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4069 - output_1_loss: 0.4037 - output_2_loss: 0.3515 - val_loss: 2.4749 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3593 - lr: 1.6970e-06\n",
            "Epoch 186/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4116 - output_1_loss: 0.4060 - output_2_loss: 0.3446 - val_loss: 2.4912 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3763 - lr: 1.6801e-06\n",
            "Epoch 187/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4194 - output_1_loss: 0.4066 - output_2_loss: 0.3494\n",
            "Epoch 187: ReduceLROnPlateau reducing learning rate to 8.317051651829388e-07.\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4194 - output_1_loss: 0.4066 - output_2_loss: 0.3494 - val_loss: 2.4712 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3552 - lr: 1.6634e-06\n",
            "Epoch 188/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.3902 - output_1_loss: 0.4017 - output_2_loss: 0.3450 - val_loss: 2.4699 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3548 - lr: 8.2343e-07\n",
            "Epoch 189/1000\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.4205 - output_1_loss: 0.4062 - output_2_loss: 0.3526 - val_loss: 2.4686 - val_output_1_loss: 0.4155 - val_output_2_loss: 0.3541 - lr: 8.1524e-07\n",
            "Epoch 190/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.3997 - output_1_loss: 0.4029 - output_2_loss: 0.3483 - val_loss: 2.4723 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3572 - lr: 8.0712e-07\n",
            "Epoch 191/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4145 - output_1_loss: 0.4056 - output_2_loss: 0.3494 - val_loss: 2.4695 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3545 - lr: 7.9909e-07\n",
            "Epoch 192/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4161 - output_1_loss: 0.4061 - output_2_loss: 0.3489 - val_loss: 2.4691 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3541 - lr: 7.9114e-07\n",
            "Epoch 193/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4124 - output_1_loss: 0.4050 - output_2_loss: 0.3504 - val_loss: 2.4692 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3544 - lr: 7.8327e-07\n",
            "Epoch 194/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4207 - output_1_loss: 0.4074 - output_2_loss: 0.3470 - val_loss: 2.4700 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3549 - lr: 7.7548e-07\n",
            "Epoch 195/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4081 - output_1_loss: 0.4041 - output_2_loss: 0.3509 - val_loss: 2.4695 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3541 - lr: 7.6776e-07\n",
            "Epoch 196/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4262 - output_1_loss: 0.4082 - output_2_loss: 0.3482 - val_loss: 2.4710 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3559 - lr: 7.6012e-07\n",
            "Epoch 197/1000\n",
            "141/141 [==============================] - 9s 61ms/step - loss: 2.4188 - output_1_loss: 0.4061 - output_2_loss: 0.3514 - val_loss: 2.4712 - val_output_1_loss: 0.4159 - val_output_2_loss: 0.3549 - lr: 7.5256e-07\n",
            "Epoch 198/1000\n",
            "141/141 [==============================] - 7s 51ms/step - loss: 2.4221 - output_1_loss: 0.4066 - output_2_loss: 0.3523 - val_loss: 2.4698 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3543 - lr: 7.4507e-07\n",
            "Epoch 199/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4051 - output_1_loss: 0.4038 - output_2_loss: 0.3494 - val_loss: 2.4698 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3544 - lr: 7.3766e-07\n",
            "Epoch 200/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.3998 - output_1_loss: 0.4033 - output_2_loss: 0.3464 - val_loss: 2.4734 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3579 - lr: 7.3032e-07\n",
            "Epoch 201/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4054 - output_1_loss: 0.4043 - output_2_loss: 0.3472\n",
            "Epoch 201: ReduceLROnPlateau reducing learning rate to 3.6152488291918417e-07.\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4054 - output_1_loss: 0.4043 - output_2_loss: 0.3472 - val_loss: 2.4741 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3584 - lr: 7.2305e-07\n",
            "Epoch 202/1000\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.4263 - output_1_loss: 0.4082 - output_2_loss: 0.3485 - val_loss: 2.4696 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3546 - lr: 3.5793e-07\n",
            "Epoch 203/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4050 - output_1_loss: 0.4052 - output_2_loss: 0.3422 - val_loss: 2.4699 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3547 - lr: 3.5437e-07\n",
            "Epoch 204/1000\n",
            "141/141 [==============================] - 8s 53ms/step - loss: 2.4066 - output_1_loss: 0.4044 - output_2_loss: 0.3477 - val_loss: 2.4698 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3546 - lr: 3.5084e-07\n",
            "Epoch 205/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.3928 - output_1_loss: 0.4021 - output_2_loss: 0.3457 - val_loss: 2.4700 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3547 - lr: 3.4735e-07\n",
            "Epoch 206/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4010 - output_1_loss: 0.4015 - output_2_loss: 0.3564 - val_loss: 2.4700 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3542 - lr: 3.4389e-07\n",
            "Epoch 207/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4144 - output_1_loss: 0.4053 - output_2_loss: 0.3510 - val_loss: 2.4701 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3547 - lr: 3.4047e-07\n",
            "Epoch 208/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4013 - output_1_loss: 0.4033 - output_2_loss: 0.3481 - val_loss: 2.4707 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3552 - lr: 3.3708e-07\n",
            "Epoch 209/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4154 - output_1_loss: 0.4056 - output_2_loss: 0.3506 - val_loss: 2.4693 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3540 - lr: 3.3373e-07\n",
            "Epoch 210/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4169 - output_1_loss: 0.4061 - output_2_loss: 0.3496 - val_loss: 2.4703 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3546 - lr: 3.3041e-07\n",
            "Epoch 211/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4110 - output_1_loss: 0.4048 - output_2_loss: 0.3504 - val_loss: 2.4690 - val_output_1_loss: 0.4156 - val_output_2_loss: 0.3540 - lr: 3.2712e-07\n",
            "Epoch 212/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4144 - output_1_loss: 0.4065 - output_2_loss: 0.3453 - val_loss: 2.4691 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3540 - lr: 3.2387e-07\n",
            "Epoch 213/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4050 - output_1_loss: 0.4035 - output_2_loss: 0.3506 - val_loss: 2.4695 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3541 - lr: 3.2064e-07\n",
            "Epoch 214/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4093 - output_1_loss: 0.4053 - output_2_loss: 0.3459 - val_loss: 2.4701 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3545 - lr: 3.1745e-07\n",
            "Epoch 215/1000\n",
            "141/141 [==============================] - ETA: 0s - loss: 2.4050 - output_1_loss: 0.4044 - output_2_loss: 0.3461\n",
            "Epoch 215: ReduceLROnPlateau reducing learning rate to 1.571473262629297e-07.\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4050 - output_1_loss: 0.4044 - output_2_loss: 0.3461 - val_loss: 2.4703 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3544 - lr: 3.1429e-07\n",
            "Epoch 216/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4018 - output_1_loss: 0.4038 - output_2_loss: 0.3462 - val_loss: 2.4699 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3542 - lr: 1.5558e-07\n",
            "Epoch 217/1000\n",
            "141/141 [==============================] - 7s 52ms/step - loss: 2.4116 - output_1_loss: 0.4051 - output_2_loss: 0.3492 - val_loss: 2.4695 - val_output_1_loss: 0.4157 - val_output_2_loss: 0.3541 - lr: 1.5404e-07\n",
            "Epoch 218/1000\n",
            "141/141 [==============================] - 7s 53ms/step - loss: 2.4091 - output_1_loss: 0.4043 - output_2_loss: 0.3510 - val_loss: 2.4696 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3540 - lr: 1.5250e-07\n",
            "Epoch 219/1000\n",
            "141/141 [==============================] - 8s 56ms/step - loss: 2.4006 - output_1_loss: 0.4034 - output_2_loss: 0.3470 - val_loss: 2.4698 - val_output_1_loss: 0.4158 - val_output_2_loss: 0.3541 - lr: 1.5099e-07\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff99c042c70>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(img_train, [rating_train, gender_train], batch_size = 25, epochs = 1000, verbose = 1, \n",
        "          callbacks = required_callbacks, validation_data = (img_val, [rating_val, gender_val]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF9joMfTQNs7",
        "outputId": "45c43440-cf44-4c00-cc99-d7618bf1b3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 3s 68ms/step - loss: 2.4002 - output_1_loss: 0.3994 - output_2_loss: 0.3663\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(img_test, [rating_test, gender_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueYt8WQF_loS",
        "outputId": "90a04cd4-cc46-4ddc-cc45-0217127f0a52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6319892143162128"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sqrt(results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e7gwzvt9bsX",
        "outputId": "c81d983c-0771-49c3-f5d8-d9a1754c3a7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 245). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model_path = '/content/drive/MyDrive/Inception_Resnet_V2'\n",
        "model.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl1Y-RTDt7gZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceh-gg8duD4n"
      },
      "source": [
        "## 4. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRSHRHcsuCQc"
      },
      "outputs": [],
      "source": [
        "#model = tf.keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krnqNJIPvVZi"
      },
      "outputs": [],
      "source": [
        "scut_dir = '/content/drive/MyDrive/SCUT-FBP/'\n",
        "mebeauty_dir = '/content/drive/MyDrive/MEBeauty/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIiQ4qPGzeMj"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1u2kIMVulZx"
      },
      "source": [
        "### 4.1 SCUT-FBP Test Dataset Preparation and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRnEKTuTu1-V",
        "outputId": "501b344a-1019-429b-ce91-ed14c07f1d9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:25<00:00, 19.69it/s]\n"
          ]
        }
      ],
      "source": [
        "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
        "\n",
        "rating_df = pd.read_excel(scut_dir + 'Rating_Collection/Rating_Collection/Attractiveness label.xlsx', header = 0)\n",
        "img_arr = np.zeros([len(rating_df), 112, 112, 3])\n",
        "y_arr = np.zeros([len(rating_df), 2])\n",
        "\n",
        "for i in tqdm(range(len(rating_df))):\n",
        "    num = rating_df.iloc[i, 0]\n",
        "    img = cv2.imread(scut_dir + 'Data_Collection/SCUT-FBP-' + str(num) + '.jpg')\n",
        "    \n",
        "    with mp_selfie_segmentation.SelfieSegmentation(model_selection = 0) as selfie_segmentation:\n",
        "        results = selfie_segmentation.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        condition = np.stack((results.segmentation_mask, ) * 3, axis = -1) > 0.1\n",
        "        bg_image = np.zeros(img.shape, dtype = np.uint8)\n",
        "        bg_image[:] = (255, 255, 255)\n",
        "        cleaned_img = np.where(condition, img, bg_image)\n",
        "    \n",
        "    cleaned_img = tf.keras.layers.Resizing(112, 112)(cleaned_img)\n",
        "    cleaned_img /= 255\n",
        "    img_arr[i] = cleaned_img\n",
        "    \n",
        "    y_arr[i, 0] = rating_df.iloc[i, 1]\n",
        "    y_arr[i, 1] = 1\n",
        "    \n",
        "#np.save(scut_dir + 'img_arr.npy', img_arr)\n",
        "#np.save(scut_dir + 'y_arr.npy', y_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln80ZFhSu7dX"
      },
      "outputs": [],
      "source": [
        "#img_arr = np.load(scut_dir + 'img_arr.npy')\n",
        "#y_arr = np.load(scut_dir + 'y_arr.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imzfDSjTvDXd",
        "outputId": "80e8d237-9509-404e-f67d-fac480a17620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 53ms/step - loss: 7.9874 - output_1_loss: 0.6555 - output_2_loss: 4.6732\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(img_arr, [y_arr[:, 0], y_arr[:, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xu8eiQA0-w-",
        "outputId": "d4682655-2f2a-47f1-ab22-27d10734bee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.8096110997434255\n"
          ]
        }
      ],
      "source": [
        "print('RMSE: '+str(np.sqrt(results[1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OplVqHHYuqS9"
      },
      "source": [
        "### 4.2 MEBeauty Test Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvMlNIuEuN4_",
        "outputId": "42d67149-6b81-4223-d33e-d8dced6e11fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2459/2459 [23:50<00:00,  1.72it/s]\n"
          ]
        }
      ],
      "source": [
        "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
        "\n",
        "rating_df = pd.read_csv(mebeauty_dir + 'landmarks.csv', header = 0)\n",
        "#img_arr = np.zeros([len(rating_df), 224, 224, 3])\n",
        "#y_arr = np.zeros([len(rating_df), 2])\n",
        "\n",
        "img_list = []\n",
        "y_list = []\n",
        "\n",
        "for i in tqdm(range(len(rating_df))):\n",
        "    file_path = rating_df.iloc[i, 1]\n",
        "    file_name = '/'.join(file_path.split('/')[5:])\n",
        "    gender = file_path.split('/')[5]   \n",
        "    try:\n",
        "        img = cv2.imread(mebeauty_dir + 'cropped_images/images_crop_align_mtcnn/' + file_name)\n",
        "        '''\n",
        "        with mp_selfie_segmentation.SelfieSegmentation(model_selection = 0) as selfie_segmentation:\n",
        "            results = selfie_segmentation.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "            condition = np.stack((results.segmentation_mask, ) * 3, axis = -1) > 0.1\n",
        "            bg_image = np.zeros(img.shape, dtype = np.uint8)\n",
        "            bg_image[:] = (255, 255, 255)\n",
        "            cleaned_img = np.where(condition, img, bg_image)\n",
        "        '''\n",
        "\n",
        "        img = tf.keras.layers.Resizing(112, 112)(img)\n",
        "        img /= 255\n",
        "        #img_arr[i] = img\n",
        "        img = img[np.newaxis, :, :, :]\n",
        "        img_list.append(img)\n",
        "        \n",
        "        if gender == 'female':\n",
        "            #y_arr[i, 1] = 1\n",
        "            y_list.append(np.array([rating_df.iloc[i, 2] / 2, 1]).reshape(1, 2))\n",
        "        else:\n",
        "            #y_arr[i, 1] = 0\n",
        "            y_list.append(np.array([rating_df.iloc[i, 2] / 2, 0]).reshape(1, 2))\n",
        "            \n",
        "        #y_arr[i, 0] = rating_df.iloc[i, 2]\n",
        "    except:\n",
        "        continue\n",
        "    \n",
        "img_arr = np.concatenate(img_list, axis = 0)\n",
        "y_arr = np.concatenate(y_list, axis = 0)\n",
        "    \n",
        "#np.save(mebeauty_dir + 'img_arr.npy', img_arr)\n",
        "#np.save(mebeauty_dir + 'y_arr.npy', y_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGo9cl7uvGpl"
      },
      "outputs": [],
      "source": [
        "#img_arr = np.load(mebeauty_dir + 'img_arr.npy')\n",
        "#y_arr = np.load(mebeauty_dir + 'y_arr.npy')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}